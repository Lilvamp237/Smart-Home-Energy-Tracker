{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "429ee3e4",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e173a0",
   "metadata": {},
   "source": [
    "## 2. Connect to Database and Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database connection\n",
    "engine = create_engine('sqlite:///refit_energy_data.db')\n",
    "\n",
    "# Query data for Aggregate meter\n",
    "query = \"\"\"\n",
    "SELECT timestamp, power_w \n",
    "FROM energy_readings \n",
    "WHERE meter_id = 'Aggregate'\n",
    "ORDER BY timestamp\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, engine)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "print(f\"Loaded {len(df)} records\")\n",
    "print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d916da",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708bf437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time-based features\n",
    "df['hour_of_day'] = df['timestamp'].dt.hour\n",
    "df['day_of_week'] = df['timestamp'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "df['day_of_year'] = df['timestamp'].dt.dayofyear\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)  # Saturday/Sunday\n",
    "\n",
    "# Display feature statistics\n",
    "print(\"Feature Engineering Complete!\")\n",
    "print(\"\\nFeature Statistics:\")\n",
    "print(df[['hour_of_day', 'day_of_week', 'day_of_year', 'month', 'is_weekend', 'power_w']].describe())\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663d0943",
   "metadata": {},
   "source": [
    "## 4. Prepare Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47856de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "feature_columns = ['hour_of_day', 'day_of_week', 'day_of_year', 'month', 'is_weekend']\n",
    "X = df[feature_columns]\n",
    "y = df['power_w']\n",
    "\n",
    "# Split data: 90% training, 10% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, shuffle=False  # Don't shuffle to maintain time order\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "print(f\"\\nFeatures used: {feature_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d3a90c",
   "metadata": {},
   "source": [
    "## 5. Train the Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8f76e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "print(f\"\\nModel Coefficients:\")\n",
    "for feature, coef in zip(feature_columns, model.coef_):\n",
    "    print(f\"  {feature}: {coef:.4f}\")\n",
    "print(f\"  Intercept: {model.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c206f674",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05865e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model Performance Metrics:\")\n",
    "print(f\"  Mean Absolute Error (MAE): {mae:.2f} W\")\n",
    "print(f\"  Root Mean Squared Error (RMSE): {rmse:.2f} W\")\n",
    "print(f\"  R² Score: {r2:.4f}\")\n",
    "print(f\"\\nAverage actual power: {y_test.mean():.2f} W\")\n",
    "print(f\"Average predicted power: {y_pred.mean():.2f} W\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfbdf33",
   "metadata": {},
   "source": [
    "## 7. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1178adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test.values[:100], label='Actual', marker='o', markersize=4)\n",
    "plt.plot(y_pred[:100], label='Predicted', marker='x', markersize=4)\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Power (W)')\n",
    "plt.title('Actual vs Predicted Energy Usage (First 100 Test Samples)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Power (W)')\n",
    "plt.ylabel('Predicted Power (W)')\n",
    "plt.title('Actual vs Predicted Power Consumption')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cf2103",
   "metadata": {},
   "source": [
    "## 8. Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24720dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize the model using joblib\n",
    "model_filename = 'energy_predictor_model.joblib'\n",
    "joblib.dump(model, model_filename)\n",
    "\n",
    "print(f\"Model saved successfully to '{model_filename}'!\")\n",
    "print(f\"\\nModel details:\")\n",
    "print(f\"  Type: {type(model).__name__}\")\n",
    "print(f\"  Features: {feature_columns}\")\n",
    "print(f\"  Training samples: {len(X_train)}\")\n",
    "print(f\"  MAE: {mae:.2f} W\")\n",
    "print(f\"  R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a12df4",
   "metadata": {},
   "source": [
    "## 9. Test Model Loading (Verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f94a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and verify it works\n",
    "loaded_model = joblib.load(model_filename)\n",
    "\n",
    "# Make a test prediction\n",
    "test_sample = X_test.iloc[:1]\n",
    "prediction = loaded_model.predict(test_sample)\n",
    "\n",
    "print(\"Model loading test successful!\")\n",
    "print(f\"\\nTest input features:\")\n",
    "print(test_sample)\n",
    "print(f\"\\nPredicted power: {prediction[0]:.2f} W\")\n",
    "print(f\"Actual power: {y_test.iloc[0]:.2f} W\")\n",
    "print(f\"\\nThe model is ready for deployment in Flask API!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
